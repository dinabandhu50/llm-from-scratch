{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![BIg Picture](./images/chapter-1/big-picture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary\n",
    "- LLMs have transformed the field of natural language processing, which previ- ously mostly relied on explicit rule-based systems and simpler statistical meth- ods. The advent of LLMs introduced new deep learning-driven approaches that led to advancements in understanding, generating, and translating human language.  \n",
    "- Modern LLMs are trained in two main steps:  \n",
    "    – First, they are pretrained on a large corpus of unlabeled text by using the prediction of the next word in a sentence as a label.  \n",
    "    – Then, they are fine-tuned on a smaller, labeled target dataset to follow instructions or perform classification tasks.  \n",
    "- LLMs are based on the transformer architecture. The key idea of the transformer architecture is an attention mechanism that gives the LLM selective access to the whole input sequence when generating the output one word at a time.  \n",
    "- The original transformer architecture consists of an encoder for parsing text and a decoder for generating text.  \n",
    "- LLMs for generating text and following instructions, such as GPT-3 and ChatGPT, only implement decoder modules, simplifying the architecture.  \n",
    "- Large datasets consisting of billions of words are essential for pretraining LLMs.  \n",
    "- While the general pretraining task for GPT-like models is to predict the next word in a sentence, these LLMs exhibit emergent properties, such as capabili- ties to classify, translate, or summarize texts.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
